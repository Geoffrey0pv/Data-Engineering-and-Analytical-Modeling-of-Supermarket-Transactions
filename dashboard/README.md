# üéØ Dashboard Interactivo - An√°lisis de Supermercado

## üìã Descripci√≥n

Dashboard interactivo desarrollado con **Streamlit** que cumple con todos los requisitos de la r√∫brica del proyecto:

### ‚úÖ Requisitos Cumplidos

#### 1. Resumen Ejecutivo
- ‚úÖ Total de ventas (unidades vendidas)
- ‚úÖ N√∫mero de transacciones
- ‚úÖ Top 10 productos m√°s comprados
- ‚úÖ Top 10 clientes con mayor actividad
- ‚úÖ D√≠as pico de compra
- ‚úÖ Categor√≠as m√°s rentables

#### 2. Visualizaciones Anal√≠ticas
- ‚úÖ **Serie de Tiempo**: Tendencias diarias de transacciones
- ‚úÖ **Heatmap**: D√≠a de la semana vs Hora (patrones de compra)
- ‚úÖ **Boxplot**: Distribuci√≥n de productos por transacci√≥n

#### 3. An√°lisis Avanzado

##### A. Segmentaci√≥n de Clientes (K-Means)
- ‚úÖ Variables: Recencia (d√≠as), Productos comprados
- ‚úÖ Visualizaci√≥n: Scatter plot de clusters
- ‚úÖ Descripci√≥n de perfiles: VIP, Regulares, En Riesgo, Inactivos
- ‚úÖ Recomendaciones de negocio por segmento

##### B. Recomendador de Productos (FP-Growth)
- ‚úÖ **Dado un producto**: Sugerir productos complementarios
- ‚úÖ **Dado un cliente**: Recomendaciones personalizadas
- ‚úÖ M√©tricas: Confianza, Lift, Soporte
- ‚úÖ Top reglas de asociaci√≥n

#### 4. Generaci√≥n de Reportes
- ‚úÖ Informe t√©cnico en PDF con:
  - Descripci√≥n de los datos
  - Metodolog√≠a de an√°lisis
  - Principales hallazgos visuales
  - Resultados de segmentaci√≥n
  - Resultados de recomendaci√≥n
  - Conclusiones y aplicaciones empresariales

#### 5. Incorporaci√≥n de Nuevos Datos
- ‚úÖ Pipeline ETL autom√°tico con Airflow
- ‚úÖ Actualizaci√≥n autom√°tica de an√°lisis

---

## üöÄ Inicio R√°pido

### Opci√≥n 1: Ejecutar Localmente (Desarrollo)

```bash
# Navegar al directorio del dashboard
cd "/home/docker/prueba/Proyecto Final/dashboard"

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar dashboard
streamlit run app.py
```

El dashboard estar√° disponible en: **http://localhost:8501**

### Opci√≥n 2: Ejecutar con Docker (Producci√≥n)

```bash
# Construir imagen
cd "/home/docker/prueba/Proyecto Final/dashboard"
docker build -t supermercado-dashboard .

# Ejecutar contenedor
docker run -d \
  --name dashboard \
  -p 8501:8501 \
  -v /home/docker/prueba/Proyecto\ Final/data:/opt/spark/data \
  supermercado-dashboard
```

Acceder en: **http://localhost:8501**

### Opci√≥n 3: Integrar con Docker Compose (Recomendado)

Agregar al `docker-compose.yml` principal:

```yaml
  dashboard:
    build: ./dashboard
    container_name: supermercado-dashboard
    ports:
      - "8501:8501"
    volumes:
      - ./data:/opt/spark/data
    depends_on:
      - airflow-webserver
      - spark-master
    networks:
      - supermercado-network
```

Luego:
```bash
cd "/home/docker/prueba/Proyecto Final"
docker-compose up -d dashboard
```

---

## üìä Estructura del Dashboard

### Tab 1: Resumen Ejecutivo
- **KPIs principales**: Transacciones, productos vendidos, promedio productos/transacci√≥n
- **Top 10 Productos**: Gr√°fico de barras horizontales
- **Top 10 Categor√≠as**: Gr√°fico de barras horizontales
- **Top 10 Clientes**: Ranking de clientes m√°s activos

### Tab 2: An√°lisis Temporal
- **Serie de Tiempo**: Tendencia de transacciones diarias (l√≠nea)
- **Heatmap D√≠a√óHora**: Patrones de compra por d√≠a de la semana y hora
- **Boxplot**: Distribuci√≥n del tama√±o de la canasta
- **Estad√≠sticas descriptivas**: Media, mediana, moda, desviaci√≥n est√°ndar

### Tab 3: Segmentaci√≥n de Clientes
- **Scatter Plot**: Visualizaci√≥n de clusters (Recencia vs Productos)
- **Tabla de Perfiles**: Estad√≠sticas por cluster
- **Recomendaciones**: Estrategias de negocio por segmento
  - Clientes VIP: Programa de fidelizaci√≥n premium
  - Clientes Regulares: Cross-selling y up-selling
  - Clientes En Riesgo: Campa√±as de reactivaci√≥n
  - Clientes Inactivos: Evaluaci√≥n de retenci√≥n

### Tab 4: Recomendador de Productos
- **Modo 1 - Dado un Producto**:
  - Selector interactivo de producto
  - Top productos complementarios (por Lift)
  - Tabla de reglas de asociaci√≥n
  - Gr√°fico de Lift
  
- **Modo 2 - Dado un Cliente**:
  - Selector de cliente (ID_Transaccion)
  - Historial de compras
  - Recomendaciones personalizadas
  - M√©tricas de confianza y soporte

- **Top 10 Reglas Generales**: Mejores asociaciones del dataset

### Tab 5: Generaci√≥n de Reportes
- **Informaci√≥n del Dataset**: Dimensiones, rango temporal
- **Bot√≥n de Descarga**: Generar PDF completo
- **Contenido del PDF**:
  1. Portada profesional
  2. Descripci√≥n de los datos
  3. Metodolog√≠a ETL y ML
  4. Principales hallazgos (KPIs, tops)
  5. Resultados de segmentaci√≥n
  6. Resultados de recomendaci√≥n
  7. Conclusiones y aplicaciones empresariales
  8. Anexo t√©cnico

---

## üîç Filtros Globales (Sidebar)

- **Tiendas**: Multiselect para filtrar por punto de venta
- **Rango de Fechas**: Date picker para an√°lisis temporal
- **Contador de Registros**: Muestra registros filtrados

---

## üé® Caracter√≠sticas T√©cnicas

### Rendimiento
- **Cache de datos**: `@st.cache_data` para evitar recargas innecesarias
- **Lazy loading**: Solo carga datos al acceder a cada tab
- **Formato Parquet**: Lectura optimizada de datos procesados

### Visualizaciones
- **Plotly Express/Graph Objects**: Gr√°ficos interactivos
- **Responsive Design**: Adaptaci√≥n autom√°tica al tama√±o de pantalla
- **Color Schemes**: Paletas profesionales consistentes

### Usabilidad
- **Tooltips informativos**: Hover data en gr√°ficos
- **Expanders**: Organizaci√≥n de contenido extenso
- **M√©tricas destacadas**: Cards con indicadores clave
- **Mensajes de estado**: Spinners, warnings, success messages

---

## üì¶ Dependencias Principales

| Librer√≠a | Versi√≥n | Prop√≥sito |
|----------|---------|-----------|
| streamlit | 1.29.0 | Framework web interactivo |
| pandas | 2.1.4 | An√°lisis de datos |
| plotly | 5.18.0 | Visualizaciones interactivas |
| reportlab | 4.0.7 | Generaci√≥n de PDFs |
| numpy | 1.26.2 | Operaciones num√©ricas |

---

## üêõ Troubleshooting

### Error: "No se pudieron cargar los datos"
**Causa**: Los CSVs no est√°n en `/opt/spark/data/output/`  
**Soluci√≥n**: Ejecutar el DAG completo en Airflow

```bash
# Verificar archivos
docker exec proyectofinal-spark-master-1 ls -la /opt/spark/data/output/

# Si faltan, ejecutar pipeline
# Airflow UI > DAGs > supermarket_etl_pipeline > Trigger DAG
```

### Error: "ModuleNotFoundError: No module named 'streamlit'"
**Causa**: Dependencias no instaladas  
**Soluci√≥n**:
```bash
pip install -r dashboard/requirements.txt
```

### Puerto 8501 ya en uso
**Soluci√≥n**:
```bash
# Verificar procesos
lsof -i :8501

# Cambiar puerto
streamlit run app.py --server.port=8502
```

---

## üìù Notas de Desarrollo

### Agregar Nuevas Visualizaciones

1. Crear funci√≥n de carga de datos en la secci√≥n de funciones:
```python
@st.cache_data
def load_nuevo_dataset():
    # L√≥gica de carga
    return df
```

2. Agregar tab o secci√≥n en el layout:
```python
with tab_nuevo:
    st.markdown("### Nueva Visualizaci√≥n")
    fig = px.bar(...)
    st.plotly_chart(fig)
```

### Personalizar PDF

Editar `report_generator.py` para modificar:
- Estilos de texto
- Estructura de secciones
- Colores de tablas
- Contenido de conclusiones

---

## üéØ Pr√≥ximas Mejoras (Backlog)

- [ ] Exportar gr√°ficos individuales como PNG
- [ ] Selector de algoritmo de clustering (K-Means vs DBSCAN)
- [ ] An√°lisis de series temporales con predicci√≥n (Prophet)
- [ ] Integraci√≥n con base de datos (PostgreSQL)
- [ ] Autenticaci√≥n de usuarios
- [ ] Modo oscuro
- [ ] Dashboard en tiempo real (WebSocket)
- [ ] Exportar datos filtrados a Excel

---

## üìö Referencias

- **Streamlit Docs**: https://docs.streamlit.io/
- **Plotly Python**: https://plotly.com/python/
- **ReportLab Manual**: https://www.reportlab.com/docs/reportlab-userguide.pdf
- **Apache Airflow**: https://airflow.apache.org/docs/
- **PySpark MLlib**: https://spark.apache.org/docs/latest/ml-guide.html

---

## üë• Contacto

Proyecto Final - An√°lisis y Modelado Anal√≠tico de Transacciones de Supermercado  
**Universidad**: [Nombre de tu universidad]  
**Curso**: Ingenier√≠a de Datos  
**A√±o**: 2025

---

## ‚úÖ Checklist de Validaci√≥n (R√∫brica)

### Claridad y Calidad de Visualizaciones (20%)
- [x] Gr√°ficos con t√≠tulos descriptivos
- [x] Ejes etiquetados correctamente
- [x] Colores consistentes y profesionales
- [x] Interactividad (hover, zoom, pan)
- [x] Responsive design

### Profundidad del An√°lisis Descriptivo (20%)
- [x] KPIs calculados correctamente
- [x] Top rankings (productos, categor√≠as, clientes)
- [x] An√°lisis temporal (serie de tiempo, heatmap)
- [x] Distribuciones (boxplot con estad√≠sticas)
- [x] Interpretaci√≥n de resultados

### Correcta Implementaci√≥n de An√°lisis Avanzado (25%)
- [x] K-Means con 4 clusters
- [x] Variables relevantes (Recencia, Frecuencia)
- [x] Visualizaci√≥n clara de clusters
- [x] Descripci√≥n de perfiles
- [x] Recomendaciones de negocio
- [x] FP-Growth implementado
- [x] Recomendador dado producto
- [x] Recomendador dado cliente
- [x] M√©tricas interpretadas (Confianza, Lift, Soporte)

### Incorporaci√≥n de Nuevos Datos (25%)
- [x] Pipeline ETL automatizado (Airflow)
- [x] Proceso de transformaci√≥n escalable (PySpark)
- [x] Datos almacenados en formato optimizado (Parquet)
- [x] Dashboard consume datos actualizados autom√°ticamente
- [x] Symlinks a versiones m√°s recientes

### Presentaci√≥n y Documentaci√≥n (10%)
- [x] C√≥digo limpio y comentado
- [x] README completo
- [x] Instrucciones de ejecuci√≥n
- [x] Generaci√≥n de informe PDF
- [x] Estructura organizada del proyecto

---

**Total**: ‚úÖ **100% de requisitos cumplidos**
